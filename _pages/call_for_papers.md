---
layout: page
permalink: /cfp/
title: call for papers
description: FoPt 2025 welcomes submissions in a single non-archival track
nav: true
nav_order: 3
---

The First Workshop on the Foundations of Post-training (FoPt 2025) invites submissions of abstracts addressing theoretical and empirical challenges in post training in a single non-archival track. Submitted abstracts can be up to one page long, and accepted abstracts will be presented as posters at the workshop. Authors are also allowed to submit, in lieu of an abstract, papers which have already appeared at a previous conference, or published to Arxiv. The review process will be single-blind (non-anonymized submissions).

The workshop solicits contributions addressing fundamental questions related to post-training in various levels of abstraction, including but not limited to the following topics of interest:

- **Statistical and computational foundations of alignment:** Eg. sample efficiency of fine-tuning methods
- **Optimization landscape of post-training:** Eg. stability and convergence guarantees
- **Statistical and computational limits of inference-time alignment**
- **Understanding models of supervision:** Eg. offline vs. online / rewards vs. comparison feedback
- **New formalizations of generalization:** Eg. In-context learning, length generalization
- **New learning paradigms:** Eg. weak-to-strong generalization, self-improvement
- **Abstract models of language generation and reasoning:** Eg. chain-of-thought
- **Other topics:** Theoretical foundations of LLMs (Eg. representation power, optimization landscape of transformers)


Paper submissions are due on **Monday, May 19th, 2025** and notifications will tentatively be sent out on the 26th of May.

### Important dates
(All dates are in 2025)

- Submission deadline: Monday, May 19th, 5:00 PM EST
- Author notification: Monday, May 26th
- Workshop date: Monday, June 30th

### Dual submission policy

Since the workshop is non-archival, FoPt invites submissions that may be substantially similar to papers that have previously been published, accepted for publication, or submitted in parallel to a peer-reviewed conference or journal. Submitted abstracts need not be anonymized.

## Submission Instructions

### Formatting and anonymization

Submitted abstracts are limited to one page, excluding references. However, authors are permitted to submitted papers which have already previously appeared in a conference, journal or workshop, or published to Arxiv. There is no formatting constraint on such papers.

<!-- An additional supplementary file may be uploaded that can include unlimited appendices. Appendices must be uploaded as a separate file. -->

<!-- All details, proofs and derivations required to substantiate the results must be included in the submission, or possibly in the appendices. However, submissions will be judged primarily based on the main paper (without appendices), and so enough details, including proof details, must be provided in the main text to convince the reviewers of the submissionsâ€™ merits. -->

**Anonymization:** Submissions should be suitable for single-blind reviewing; in particular, submissions are permitted to include author names and other identifying information. Reviewer names are withheld from the authors.

**Style files:** For submitted one-page abstracts, please use the COLT style file, linked below.

- [LaTeX style files and template](https://learningtheory.org/colt2025/COLT2025_style.zip)

For papers which have previously appeared at a conference/journal/workshop/Arxiv, there is no page limit or formatting constraint.

### Submitting your paper

Papers should be submitted through Openreview; the deadline for submissions is 5pm EST on Monday, May 19th, 2025.

Openreview submission site: 